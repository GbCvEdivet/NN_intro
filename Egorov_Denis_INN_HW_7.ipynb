{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a518d5",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1904.08189\n",
    "\n",
    "краткий обзор CenterNet\n",
    "https://arxiv.org/pdf/1904.08189.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854718f",
   "metadata": {},
   "source": [
    "RetinaNet, Faster R-CNN, SSD это сети, спроектированные на 'anchor-based' принципе. Принцип этот подразумевает использование предопределенных \"bounding-box\" фиксированного размера, сопоставление anchor с bounding-box объектов, присутствующих на изображении. При этом сеть решает две задачи - определение места на изображении, где находится объект, и поределение вероятности принадлежности этого объекта к определенному классу. \n",
    "У такого подхода есть недостатки:\n",
    " - Ограниченный охват по масштабу и соотношению сторон\n",
    " - Чувствительность к конструкции анкера (anchor)\n",
    " - Трудность в обращении с окклюзией объекта (когда например объект частично перекрыт на изображении тенью или другим объектом)\n",
    " - Сложная работа с экстремальными соотношениями сторон (очень широкие или вытянутые объекты занимают малую площадь анкера и могут не распознаться)\n",
    " - Повышенная вычислительная сложность\n",
    " - Сложность в обработке вариаций объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43baad69",
   "metadata": {},
   "source": [
    "Чтобы преодолеть недостатки anchor-based подходов, авторами был предложен конвейер обнаружения объектов на основе ключевых точек, названный CornerNet. Он представлет каждый объект парой угловых ключевых точек, что позволило избежать необходимости в опорных блоках (anchor) и обеспечить точность и скорость обнаружения объектов. Тем не менее, производительность Corner Net по-прежнему ограничена ее относительно слабой способностью ссылаться на глобальную информацию об объекте. То есть,\n",
    "поскольку каждый объект состоит из пары углов, алгоритм чувствителен к обнаружению границ объектов, в то же время не зная, какие пары ключевых точек следует сгруппировать в объекты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb3d34",
   "metadata": {},
   "source": [
    "\n",
    "Преимущества CornerNet перед anchor-based сетями:\n",
    "1. Точная локализация:\n",
    "Одним из ключевых преимуществ CornerNet является его способность достигать точной локализации объектов. Непосредственно предсказывая углы ограничивающего прямоугольника, CornerNet устраняет необходимость в опорных прямоугольниках, которые могут привести к ошибкам в процессе сопоставления. Это позволяет CornerNet точно локализовать объекты с различными масштабами и соотношениями сторон, что приводит к повышению точности по сравнению с методами, основанными на привязке.\n",
    "2. Неизменность масштаба и соотношения сторон:\n",
    "CornerNet по своей сути не зависит от масштаба и соотношения сторон, что означает, что он может обрабатывать объекты различных размеров и форм, не требуя четкого выбора дизайна для якорных блоков. При подходах, основанных на привязке, выбор подходящих масштабов привязки и соотношений сторон может оказаться сложной задачей, поскольку для этого требуются предварительные знания о наборе данных или ручная настройка. CornerNet позволяет избежать этой проблемы путем прямого регрессирования угловых точек, что позволяет ему эффективно обрабатывать объекты с произвольными масштабами и соотношениями сторон.\n",
    "3. Сниженная вычислительная сложность:\n",
    "Еще одним преимуществом CornerNet является его меньшая вычислительная сложность по сравнению с методами, основанными на привязке. При традиционных подходах в каждом пространственном местоположении на карте объектов генерируется большое количество опорных блоков, что приводит к значительной вычислительной нагрузке во время обучения и вывода. В отличие от этого, CornerNet требуется только предсказать угловые точки и ключевые точки объектов, что приводит к созданию более простой и эффективной структуры.\n",
    "4. Устранение окклюзий:\n",
    "CornerNet также демонстрирует улучшенную производительность при обработке закрытых объектов по сравнению с методами, основанными на привязке. Поскольку CornerNet фокусируется на прогнозировании угловых точек, а не полагается на предопределенные привязки, он может лучше справляться с перекрытиями, явно моделируя закрытые части объектов. Это позволяет CornerNet точно обнаруживать и локализовать частично видимые объекты, что может быть сложной задачей при использовании подходов, основанных на привязке.\n",
    "5. Устойчивость к деформациям объекта:\n",
    "CornerNet обладает устойчивостью к деформациям объектов, что делает его пригодным для обнаружения объектов с нежесткими конструкциями. Непосредственно предсказывая угловые точки, CornerNet может эффективно обрабатывать объекты, которые подвергаются значительным деформациям или изменениям формы. Это особенно полезно при детектировании людей и животных. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeec7ea",
   "metadata": {},
   "source": [
    "Сложности, которые могут возникнуть при работе с корнернет:\n",
    " - относительно сложная разметка данных\n",
    " - долгое обучение и предсказание (в сравнении c SSD) \n",
    " - иногда объекты могут иметь меньше видимых углов или ключевых точек по сравнению с другими, что приводит к дисбалансу в обучающих данных\n",
    " - ухудшение точности в случаях, когда тестовые изображения отличаются от тренировочных по свету, ракурсу камеры, заднему фону и т.д.\n",
    " - производительность может страдать при детекции объектов на изображениях с низким разрешением, шумами от сжатия фото и другими артефактами. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85eec25",
   "metadata": {},
   "source": [
    "1. \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\" by Shaoqing Ren et al.\n",
    "2. \"You Only Look Once: Unified, Real-Time Object Detection\" by Joseph Redmon et al.\n",
    "3. \"SSD: Single Shot MultiBox Detector\" by Wei Liu et al.\n",
    "4. Law, He, et al. \"CornerNet: Detecting Objects as Paired Keypoints.\" European Conference on Computer Vision (ECCV), 2018.\n",
    "5. Law, He, et al. \"CornerNet-Lite: Efficient Keypoint-Based Object Detection.\" Conference on Computer Vision and Pattern Recognition (CVPR), 2019.\n",
    "6. Law, He, et al. \"Cornernet-Squeeze: A Lightweight Keypoint-Based Framework for Object Detection.\" arXiv preprint arXiv:2004.04445 (2020).\n",
    "7. \"CornerNet: Detecting Objects as Paired Keypoints\" - Paper by Hei Law and Jia Deng (CVPR 2018)\n",
    "8. \"Objects as Points\" - Paper by Xingyi Zhou et al. (arXiv 2019)\n",
    "9. \"CornerNet-Lite: Efficient Keypoint-Based Object Detection\" - Paper by Hei Law et al. (CVPR 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14183f3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For running inference on the TF-Hub module.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# For downloading the image.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29e193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_kernel",
   "language": "python",
   "name": "ml_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
